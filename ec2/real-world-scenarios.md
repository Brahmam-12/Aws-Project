# DAY 3 - REAL-WORLD EC2 SCENARIOS ğŸ—ï¸

## Production-Grade Architecture Patterns

---

## Scenario 1: Scaling a Startup's Web Application

### Background
A startup has built a Node.js web app with growing traffic:
- 100 requests/second during peak
- Traffic varies throughout the day
- $500/month budget for infrastructure
- Need 99.9% uptime
- Small DevOps team (1 person)

### Current Problem
- Single t3.micro instance
- Crashes during traffic spikes
- No monitoring/alerting
- Manual restarts when it breaks

### Architecture Solution

```
                    User Traffic
                         â”‚
                         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Application Load Balancer           â”‚
    â”‚ (Always ON - On-Demand)             â”‚
    â”‚ Cost: $16/month                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“             â†“             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚EC2 #1  â”‚   â”‚EC2 #2  â”‚   â”‚EC2 #3  â”‚
    â”‚Spot    â”‚   â”‚Spot    â”‚   â”‚Spot    â”‚
    â”‚t3.smallâ”‚   â”‚t3.smallâ”‚   â”‚t3.smallâ”‚
    â”‚$0.025/hâ”‚   â”‚$0.025/hâ”‚   â”‚$0.025/hâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RDS PostgreSQL         â”‚
        â”‚ Multi-AZ (Reliable)    â”‚
        â”‚ Cost: $100/month       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Auto-Scaling Configuration:
â”œâ”€â”€ Min: 2 (high availability)
â”œâ”€â”€ Desired: 3 (baseline)
â”œâ”€â”€ Max: 10 (during viral spike)
â””â”€â”€ Metrics: CPU > 70% â†’ Add 2 instances
            CPU < 30% â†’ Remove 1 instance

Total Monthly Cost:
â”œâ”€â”€ ALB: $16
â”œâ”€â”€ 3 Ã— t3.small Spot (avg 24h): $54
â”œâ”€â”€ RDS: $100
â”œâ”€â”€ Snapshots: $15
â””â”€â”€ Total: ~$185/month âœ… (Under budget!)

Benefits:
âœ… High availability (if 1 instance dies, 2 others handle)
âœ… Auto-scales with traffic (no manual intervention)
âœ… Cost-optimized (Spot + On-Demand hybrid)
âœ… Monitoring built-in (CloudWatch)
âœ… Self-healing (bad instances replaced)
```

### Implementation Steps

```bash
# Step 1: Create security groups
aws ec2 create-security-group \
  --group-name web-app-alb-sg \
  --description "ALB security group"

aws ec2 create-security-group \
  --group-name web-app-ec2-sg \
  --description "EC2 security group"

# Step 2: Create launch template (for auto-scaling)
aws ec2 create-launch-template \
  --launch-template-name web-app-v1 \
  --launch-template-data '{
    "ImageId": "ami-0c55b...",
    "InstanceType": "t3.small",
    "UserData": "base64-encoded-user-data",
    "SecurityGroupIds": ["sg-web-app-ec2"]
  }'

# Step 3: Create Auto Scaling Group
aws autoscaling create-auto-scaling-group \
  --auto-scaling-group-name web-app-asg \
  --launch-template LaunchTemplateName=web-app-v1 \
  --min-size 2 \
  --desired-capacity 3 \
  --max-size 10 \
  --vpc-zone-identifier "subnet-1,subnet-2"

# Step 4: Create ALB
aws elbv2 create-load-balancer \
  --name web-app-alb \
  --subnets subnet-public-1 subnet-public-2 \
  --security-groups sg-web-app-alb

# Step 5: Add scaling policy
aws autoscaling put-scaling-policy \
  --auto-scaling-group-name web-app-asg \
  --policy-name scale-up \
  --policy-type TargetTrackingScaling \
  --target-tracking-configuration "TargetValue=70.0,PredefinedMetricSpecification={PredefinedMetricType=ASGAverageCPUUtilization}"
```

### Monitoring & Alerting

```
CloudWatch Alarms:

1. High CPU (Scale Up)
   â””â”€â”€ If AVG CPU > 70% for 5 min â†’ Add instances

2. Low CPU (Scale Down)
   â””â”€â”€ If AVG CPU < 30% for 10 min â†’ Remove instances

3. Unhealthy Targets
   â””â”€â”€ If any target fails health check â†’ Replace

4. RDS Connection Issues
   â””â”€â”€ Alert ops team â†’ Manual investigation

5. Cost Alert
   â””â”€â”€ Monthly bill > $250 â†’ Alert budget owner
```

### Cost Breakdown (Per Month)

```
Hour-by-hour simulation:

Midnight-8 AM (Low Traffic):
â”œâ”€â”€ ALB: Running ($16/month flat)
â”œâ”€â”€ 2 EC2 instances (min): 8 hrs Ã— 2 Ã— $0.025 = $0.40
â”œâ”€â”€ RDS: Running ($100/month flat)
â””â”€â”€ Daily cost: ~$4

8 AM-12 PM (Morning Peak):
â”œâ”€â”€ 5 instances (scaled up): 4 hrs Ã— 5 Ã— $0.025 = $0.50
â””â”€â”€ Daily addition: ~$0.50

12 PM-5 PM (Lunch â†’ Afternoon):
â”œâ”€â”€ 4 instances (scaling down): 5 hrs Ã— 4 Ã— $0.025 = $0.50
â””â”€â”€ Daily addition: ~$0.50

5 PM-Midnight (Evening):
â”œâ”€â”€ 3 instances (back to desired): 7 hrs Ã— 3 Ã— $0.025 = $0.53
â””â”€â”€ Daily addition: ~$0.50

Daily cost: ~$5.50
Monthly: 30 Ã— $5.50 = $165 + $100 RDS = $265/month

Yearly savings vs manual scaling: ~$3,000! ğŸ’°
```

---

## Scenario 2: Running Batch Processing Jobs

### Background
A data science company runs daily ML model training:
- 100 GB training dataset
- Takes 2-3 hours per job
- Runs daily at 2 AM
- Cost is highest concern

### Architecture Solution

```
Scheduled Batch Job (Using EventBridge + Auto-Scaling)

2:00 AM Daily:
     â”‚
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EventBridge     â”‚ (Free service)
â”‚ Cron trigger    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
    Lambda Function
    (Start/Stop logic)
         â”‚
         â”œâ”€â†’ GET Spot Price
         â”‚   (Check current rate)
         â”‚
         â”œâ”€â†’ Launch 10 Spot Instances
         â”‚   (c5.2xlarge - high CPU)
         â”‚   (Cost: $0.17/hr each = $1.70/hr total)
         â”‚
         â””â”€â†’ Start EC2 instances
            
Parallel Job Execution:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Instance 1 â”€â”€â†’ Training subset 1 (30 min)
Instance 2 â”€â”€â†’ Training subset 2 (30 min)
Instance 3 â”€â”€â†’ Training subset 3 (30 min)
... (10 instances total)
Instance 10 â†’ Training subset 10 (30 min)

       All done in 30 minutes! âš¡

5:00 AM:
     â”‚
     â†“
Lambda Aggregates Results
     â”‚
     â†“
Uploads to S3
     â”‚
     â†“
Terminates all Spot instances
     â”‚
     â†“
Cost: 3 hours Ã— 10 instances Ã— $0.17/hr = $5.10 âœ…

vs Daily On-Demand:
â”œâ”€â”€ 1 c5.2xlarge 24/7
â”œâ”€â”€ Cost: 365 days Ã— 24 hrs Ã— $0.34/hr = $2,982/year
â””â”€â”€ Batch approach: 365 Ã— $5.10 = $1,861/year
â””â”€â”€ Savings: $1,121/year! ğŸ’°
```

### Implementation

```bash
# Step 1: Create security group for batch jobs
aws ec2 create-security-group \
  --group-name batch-processing-sg \
  --description "Batch processing job instances"

# Step 2: Create launch template
aws ec2 create-launch-template \
  --launch-template-name batch-training-v1 \
  --launch-template-data '{
    "ImageId": "ami-batch-ml-stack",
    "InstanceType": "c5.2xlarge",
    "UserData": "#!/bin/bash\naws s3 cp s3://data-bucket/training.csv ./\npython train_model.py\naws s3 cp ./model.pkl s3://models-bucket/\n"
  }'

# Step 3: Create Spot Fleet Request (for parallel execution)
aws ec2 request-spot-fleet \
  --spot-fleet-request-config '{
    "IamFleetRole": "arn:aws:iam::123456789:role/fleet-role",
    "AllocationStrategy": "lowestPrice",
    "TargetCapacity": 10,
    "SpotPrice": "0.25",
    "LaunchSpecifications": [
      {
        "ImageId": "ami-batch-ml-stack",
        "InstanceType": "c5.2xlarge",
        "SecurityGroups": [{"GroupId": "sg-batch"}]
      }
    ]
  }'

# Step 4: Create Lambda function for orchestration
# (Pseudocode)
def batch_training_handler(event, context):
    # 1. Launch 10 Spot instances
    # 2. Wait for all to start
    # 3. Monitor training progress
    # 4. Once complete, aggregate results
    # 5. Terminate all instances
    # 6. Email results to team
    pass

# Step 5: Create EventBridge rule
aws events put-rule \
  --name daily-batch-training \
  --schedule-expression "cron(0 2 * * ? *)" \  # 2 AM UTC daily
  --state ENABLED

aws events put-targets \
  --rule daily-batch-training \
  --targets "Id"="1","Arn"="arn:aws:lambda:us-east-1:123456789:function:batch-orchestrator"
```

### Cost Comparison

| Approach | Monthly Cost | Annual | Benefit |
|----------|---|---|---|
| **Spot Batch (10 instances Ã— 3 hrs)** | $153 | $1,836 | âœ… Cheapest |
| **Reserved c5.2xlarge (always on)** | $249 | $2,988 | 62% more than batch |
| **On-Demand c5.2xlarge (always on)** | $249 | $2,988 | 62% more than batch |

**Annual Savings: $1,152!** ğŸ‰

---

## Scenario 3: Dev/Test Environment (Minimal Cost)

### Background
Small team needs dev and staging environments:
- Dev: Low traffic, always off outside work hours
- Staging: Mirror production (but smaller)
- Budget: $100/month total
- Goal: Simulate production without the cost

### Solution

```
Development Environment

Weekday 9 AM - 5 PM (Business Hours):
    Running
    â”œâ”€â”€ 1 Ã— t3.small (code development)
    â”œâ”€â”€ RDS t3.micro (test database)
    â””â”€â”€ Cost: 8 hrs Ã— 5 days Ã— ($0.025 + $0.017) = $8.40/week

After Hours / Weekends:
    STOPPED (no charges for compute)
    â””â”€â”€ Cost: Only EBS storage (~$5/month)

Monthly: ~$40 (compute) + $20 (storage) = $60

Staging Environment

Always running (mirrors production):
    â”œâ”€â”€ 1 Ã— t3.medium (similar to prod)
    â”œâ”€â”€ RDS t3.small
    â””â”€â”€ Cost: 24/7 = $60/month compute + $15 storage = $75/month

Total Monthly: $60 + $75 = $135/month

But budget is $100! Solution:
â”œâ”€â”€ Dev: Stop after hours (save $25/month)
â”œâ”€â”€ Staging: Use smaller instance (save $15/month)
â””â”€â”€ Total: ~$95/month âœ…
```

### Automation (Stop/Start Schedule)

```bash
# Use AWS Systems Manager to auto stop/start

# Create document
aws ssm create-document \
  --content '{
    "schemaVersion": "2.2",
    "description": "Stop dev instances after hours",
    "mainSteps": [
      {
        "action": "aws:executeScript",
        "name": "StopInstances",
        "inputs": {
          "Runtime": "python3.8",
          "Handler": "stop_handler",
          "Script": "..."
        }
      }
    ]
  }' \
  --name stop-dev-instances

# Create EventBridge rule
aws events put-rule \
  --name stop-dev-after-hours \
  --schedule-expression "cron(0 18 ? * MON-FRI *)"  # 6 PM weekdays

# Restart next morning
aws events put-rule \
  --name start-dev-morning \
  --schedule-expression "cron(0 8 ? * MON-FRI *)"   # 8 AM weekdays

Result:
â”œâ”€â”€ Weekday 9 AM: Auto-start dev instances
â”œâ”€â”€ Weekday 6 PM: Auto-stop dev instances
â”œâ”€â”€ Weekend: Always off
â””â”€â”€ Savings: 66% on dev compute! ğŸ’°
```

---

## Scenario 4: High-Availability Production Setup

### Background
E-commerce platform with:
- $5M revenue/year
- 99.99% uptime SLA
- Can't lose data
- Peak: 1000 requests/second
- Multi-region requirement

### Architecture Solution

```
Multi-Region, Multi-AZ Architecture

         Primary Region (us-east-1)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                    â”‚
    â”‚  AZ-1a          AZ-1b             â”‚
    â”‚  â”œâ”€â”€ ALB        â”œâ”€â”€ ALB           â”‚
    â”‚  â”‚              â”‚                 â”‚
    â”‚  â”œâ”€â”€ Web EC2    â”œâ”€â”€ Web EC2       â”‚
    â”‚  â”‚              â”‚                 â”‚
    â”‚  â””â”€â”€ App EC2    â””â”€â”€ App EC2       â”‚
    â”‚       â”‚              â”‚             â”‚
    â”‚       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
    â”‚              â”‚                     â”‚
    â”‚         RDS Primary               â”‚
    â”‚         (Multi-AZ)                â”‚
    â”‚         - Sync replication        â”‚
    â”‚         - Auto-failover           â”‚
    â”‚         - Backup: Every 1 hour    â”‚
    â”‚                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ (Cross-region replication)
             â”‚ (Read-only replicas)
             â†“
      Secondary Region (us-west-1)
      â”œâ”€â”€ Read-only RDS replica
      â”œâ”€â”€ Warm standby ASG
      â””â”€â”€ Can take over in 5 minutes

Route53 Health Checks:
â”œâ”€â”€ Primary region healthy?
â”œâ”€â”€ Yes â†’ Route 100% traffic to primary
â”œâ”€â”€ No â†’ Route to secondary (failure recovery)
â””â”€â”€ RTO: 5 minutes | RPO: 1 hour
```

### Disaster Recovery Scenarios

```
Scenario A: Single Instance Failure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. ALB health check fails (30 sec)
2. Instance marked unhealthy
3. ASG launches replacement (2 min)
4. New instance added to ALB
5. Impact: 2 seconds downtime, auto-recovered
6. Data loss: NONE (database survives)

Scenario B: Full AZ Outage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. All instances in AZ-1a offline
2. Traffic routed to AZ-1b instances
3. ASG scales up (if CPU high)
4. No traffic loss (ALB + ASG)
5. RDS Multi-AZ: Sync replica takes over (1 min)
6. Impact: 1-2 seconds
7. Data loss: NONE (Multi-AZ replicated)

Scenario C: Entire Region Outage
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. us-east-1 completely down
2. Route53 detects failure
3. Routes traffic to us-west-1 (secondary)
4. Secondary region processes requests
5. Read replicas can handle reads (no writes)
6. For writes: Manual failover (or automation)
7. Impact: 5 minutes (manual) / Immediate (automated)
8. Data loss: Up to 1 hour (RDS replica lag)

Strategy for 99.99% uptime:
â”œâ”€â”€ Instance failure: < 1 min recovery (AUTO)
â”œâ”€â”€ AZ failure: < 1 min recovery (AUTO)
â”œâ”€â”€ Region failure: 5-10 min recovery (MANUAL/AUTO)
â””â”€â”€ Result: Only 52 minutes downtime per year âœ…
```

### Cost for High Availability

```
Primary Region (us-east-1):
â”œâ”€â”€ ALB (2): $32/month
â”œâ”€â”€ EC2 instances (6 Ã— t3.large): $200/month
â”œâ”€â”€ RDS Multi-AZ: $400/month
â””â”€â”€ Subtotal: $632/month

Secondary Region (us-west-1):
â”œâ”€â”€ ALB (2): $32/month
â”œâ”€â”€ Warm standby ASG (2 Ã— t3.large): $70/month
â”œâ”€â”€ RDS Read Replica: $200/month
â””â”€â”€ Subtotal: $302/month

Data Transfer:
â”œâ”€â”€ Cross-region replication: ~$50/month
â””â”€â”€ Subtotal: $50/month

Total Monthly: $984/month

Revenue Impact:
â”œâ”€â”€ 5M/year revenue = ~$410k/month
â”œâ”€â”€ Downtime cost: $410k / 43200 min = $9.50/min
â”œâ”€â”€ 99.99% SLA prevents: 52 min downtime/year = $494 potential loss
â”œâ”€â”€ Infrastructure cost: $984/month = $11,808/year
â”œâ”€â”€ ROI: Prevents $494/year loss (not great)...

But intangible benefits:
â”œâ”€â”€ Reputation: Never goes down
â”œâ”€â”€ Customer trust: 99.99% SLA
â”œâ”€â”€ Ability to scale: Can handle spikes
â””â”€â”€ Business opportunity: Enterprise contracts
```

---

## Scenario 5: Machine Learning Inference at Scale

### Background
ML model serves 1M inference requests/day:
- Each request: 100-500 MB data
- Processing: 1-2 seconds per request
- Throughput: 100 requests/second during peak
- Latency budget: < 500ms (p99)

### Solution: GPU Instance Scaling

```
Request Flow:

User Request
     â”‚
     â”œâ”€â†’ API Gateway (auto-scale)
     â”‚
     â”œâ”€â†’ Load Balancer
     â”‚
     â”œâ”€â†’ Queue (SQS) - decouple load
     â”‚
     â”œâ”€â†’ GPU Instances (scale on queue depth)
     â”‚   â”œâ”€â”€ g4dn.xlarge (1 Ã— T4 GPU)
     â”‚   â”œâ”€â”€ g4dn.xlarge
     â”‚   â”œâ”€â”€ g4dn.xlarge
     â”‚   â””â”€â”€ g4dn.xlarge (scales to 100+)
     â”‚
     â”œâ”€â†’ Inference Server (TensorFlow, PyTorch)
     â”‚   â”œâ”€â”€ Processes 50-100 inference/sec per GPU
     â”‚   â”œâ”€â”€ Caches model in GPU memory
     â”‚   â””â”€â”€ Returns result to SQS
     â”‚
     â””â”€â†’ Result delivered to user

Peak Load Handling:

During peak (100 req/sec):
â”œâ”€â”€ 1 GPU inference: 50 req/sec
â”œâ”€â”€ Scale to: 2-3 GPU instances
â”œâ”€â”€ Cost: 2 Ã— $0.50/hour = $1/hour

Daily Cost (peak 4 hours, off 20 hours):
â”œâ”€â”€ On-demand (peak 4 hrs): 4 Ã— $1 = $4
â”œâ”€â”€ On-demand (off-peak): 0 (scaled to 0)
â”œâ”€â”€ Monthly: 30 Ã— $4 = $120

Alternative: CPU (without GPU):
â”œâ”€â”€ 1M requests Ã— 1.5 sec = 1.5M seconds = 416 hours/day
â”œâ”€â”€ Need: 416 CPU hours
â”œâ”€â”€ Cost: 416 Ã— $0.10 (c5.xlarge) = $41.60/day
â”œâ”€â”€ Monthly: 30 Ã— $41.60 = $1,248

GPU Savings: $1,248 - $120 = $1,128/month! ğŸ’°
```

### Implementation

```python
# Inference server (runs on GPU instance)

from flask import Flask, request
import torch
import numpy as np

app = Flask(__name__)

# Load model once (into GPU memory)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
model.to(device)
model.eval()

@app.route('/predict', methods=['POST'])
def predict():
    # Get input image
    data = request.json['image']  # Base64 encoded
    
    # Prepare input
    tensor = torch.from_numpy(np.array(data)).to(device)
    
    # Inference (GPU acceleration!)
    with torch.no_grad():
        output = model(tensor.unsqueeze(0))
    
    # Return prediction
    return {'prediction': output.argmax(1).item()}

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### Auto-Scaling Configuration

```bash
# Target: Process queue in 10 seconds
# If queue > 100 messages: Scale up

aws autoscaling put-scaling-policy \
  --auto-scaling-group-name ml-inference-asg \
  --policy-name queue-based-scaling \
  --policy-type TargetTrackingScaling \
  --target-tracking-configuration '{
    "CustomizedMetricSpecification": {
      "MetricName": "ApproximateNumberOfMessagesVisible",
      "Namespace": "AWS/SQS",
      "Dimensions": [
        {
          "Name": "QueueName",
          "Value": "inference-queue"
        }
      ],
      "Statistic": "Average",
      "Unit": "Count"
    },
    "TargetValue": 100.0
  }'

# Min: 1 GPU (always on for warmth)
# Max: 100 GPUs (max throughput)
# Desired: Auto-scaled based on queue
```

---

## Cost Optimization Tips for All Scenarios

```
1. Right-Size Instances
   â”œâ”€â”€ Monitor actual usage: CPU, Memory, Network
   â”œâ”€â”€ Downsize if under 30% utilization
   â””â”€â”€ Save: 40-60% per change

2. Use Spot Instances
   â”œâ”€â”€ For non-critical workloads: 70% savings
   â”œâ”€â”€ Batch jobs: 70% savings
   â””â”€â”€ Dev/test: 70% savings

3. Reserved Instances
   â”œâ”€â”€ Baseline capacity: 40% savings (1-year)
   â”œâ”€â”€ Predictable workloads: Commit upfront
   â””â”€â”€ Break-even: ~4 months

4. Stop During Off-Hours
   â”œâ”€â”€ Dev/test: Always off after hours
   â”œâ”€â”€ Non-production: Off weekends
   â”œâ”€â”€ Save: 66%+ on compute (storage remains)
   â””â”€â”€ Automate: EventBridge + Lambda

5. Multi-Region Considerations
   â”œâ”€â”€ Primary region: Full capacity
   â”œâ”€â”€ Secondary region: Warm standby (50% cost)
   â””â”€â”€ Trade-off: Cost vs. RTO

6. Data Transfer Optimization
   â”œâ”€â”€ Same AZ: Free
   â”œâ”€â”€ Cross-AZ: $0.01/GB
   â”œâ”€â”€ Cross-region: $0.02/GB
   â””â”€â”€ Design: Keep workloads in same AZ

7. Storage Optimization
   â”œâ”€â”€ General Purpose (gp3): Most use cases
   â”œâ”€â”€ Provisioned IOPS (io1): High I/O
   â”œâ”€â”€ Throughput Optimized (st1): Batch/big data
   â””â”€â”€ Delete old snapshots: Save storage

8. Reserved Capacity Planning
   â”œâ”€â”€ Buy for 70% baseline
   â”œâ”€â”€ Spot for 20% variable
   â”œâ”€â”€ On-Demand for 10% emergency
   â””â”€â”€ Result: 40-50% vs all on-demand
```

---

## Summary: Real-World Patterns

| Scenario | Instance Type | Scaling | Cost/Month | Best For |
|----------|---|---|---|---|
| **Startup** | t3.small Spot | ASG (2-10) | $185 | Growing web apps |
| **Batch ML** | c5.2xlarge Spot | Fleet of 10 | $153 | ML training, batch jobs |
| **Dev/Test** | t3.small | Scheduled stop/start | $95 | Development teams |
| **HA Prod** | m5.large Reserved | ASG (6-20) | $984 | E-commerce, SaaS |
| **ML Inference** | g4dn.xlarge Spot | Queue-based (1-100) | $120 | ML inference, real-time |

All scenarios optimize cost while maintaining required availability and performance! ğŸš€
